{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization\n",
    "\n",
    "## step 1 Text Cleaning\n",
    "## step 2 Sentence Tokenization\n",
    "## step 3 Word Tokenization\n",
    "## step 4 summarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages for this project\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eight',\n",
       " 'within',\n",
       " 'afterwards',\n",
       " 'see',\n",
       " 'amongst',\n",
       " 'several',\n",
       " 'such',\n",
       " 'five',\n",
       " 'but',\n",
       " \"'m\",\n",
       " 'have',\n",
       " 'less',\n",
       " 'most',\n",
       " 'become',\n",
       " 'without',\n",
       " 'has',\n",
       " 'give',\n",
       " 'moreover',\n",
       " 'fifty',\n",
       " 'even',\n",
       " 'i',\n",
       " '’ve',\n",
       " 'get',\n",
       " 'also',\n",
       " 'however',\n",
       " 'seems',\n",
       " 'one',\n",
       " 'during',\n",
       " 'down',\n",
       " 'once',\n",
       " 'after',\n",
       " 'many',\n",
       " 'off',\n",
       " 'various',\n",
       " 'been',\n",
       " 'were',\n",
       " 'wherein',\n",
       " 'sometimes',\n",
       " 'sixty',\n",
       " 'whereafter',\n",
       " 'either',\n",
       " 'hereupon',\n",
       " 'sometime',\n",
       " 'was',\n",
       " 'former',\n",
       " 'every',\n",
       " '‘re',\n",
       " 'else',\n",
       " 'formerly',\n",
       " 'they',\n",
       " \"n't\",\n",
       " 'what',\n",
       " 'few',\n",
       " 'indeed',\n",
       " 'part',\n",
       " 'although',\n",
       " 'hence',\n",
       " 'only',\n",
       " 'may',\n",
       " 'with',\n",
       " 'because',\n",
       " 'not',\n",
       " 'himself',\n",
       " 'well',\n",
       " 'keep',\n",
       " 'six',\n",
       " 'bottom',\n",
       " 'name',\n",
       " 'nevertheless',\n",
       " 'from',\n",
       " 'could',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'among',\n",
       " 'onto',\n",
       " 'on',\n",
       " \"'s\",\n",
       " 'it',\n",
       " 'empty',\n",
       " 'our',\n",
       " 'latter',\n",
       " 'becomes',\n",
       " 'thereupon',\n",
       " 'hereafter',\n",
       " 'least',\n",
       " 'beyond',\n",
       " 'up',\n",
       " 'go',\n",
       " 'back',\n",
       " 'anything',\n",
       " 'yet',\n",
       " 'fifteen',\n",
       " 'whether',\n",
       " 'again',\n",
       " 'he',\n",
       " 'at',\n",
       " 'my',\n",
       " 'enough',\n",
       " '’s',\n",
       " 'next',\n",
       " 'say',\n",
       " 'both',\n",
       " 'can',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whereby',\n",
       " 'ours',\n",
       " 'per',\n",
       " 'wherever',\n",
       " 'him',\n",
       " 'yours',\n",
       " 'might',\n",
       " 'ten',\n",
       " 'somehow',\n",
       " 'very',\n",
       " 'there',\n",
       " 'latterly',\n",
       " 'the',\n",
       " 'third',\n",
       " 'unless',\n",
       " 'and',\n",
       " 'under',\n",
       " 'hereby',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'each',\n",
       " '‘m',\n",
       " '’m',\n",
       " 'here',\n",
       " 'all',\n",
       " 'some',\n",
       " 'had',\n",
       " 'through',\n",
       " 'us',\n",
       " 'whither',\n",
       " 'me',\n",
       " 'her',\n",
       " 'towards',\n",
       " 'being',\n",
       " 'whereupon',\n",
       " 'beforehand',\n",
       " 'nor',\n",
       " 'ever',\n",
       " \"'re\",\n",
       " '’re',\n",
       " 'elsewhere',\n",
       " 'are',\n",
       " 'doing',\n",
       " 'full',\n",
       " 'be',\n",
       " 'yourself',\n",
       " 'where',\n",
       " '‘d',\n",
       " 'perhaps',\n",
       " 'via',\n",
       " 'move',\n",
       " 'whenever',\n",
       " 'along',\n",
       " 'hundred',\n",
       " 'twelve',\n",
       " 'behind',\n",
       " 'used',\n",
       " 'make',\n",
       " '‘ll',\n",
       " 'this',\n",
       " 'using',\n",
       " 'rather',\n",
       " \"'d\",\n",
       " '’d',\n",
       " 'upon',\n",
       " 'often',\n",
       " 'so',\n",
       " 'front',\n",
       " 'anyone',\n",
       " 'its',\n",
       " 'did',\n",
       " 'do',\n",
       " 'herein',\n",
       " 'forty',\n",
       " 'around',\n",
       " 'must',\n",
       " 'made',\n",
       " 'them',\n",
       " 'first',\n",
       " 'just',\n",
       " '’ll',\n",
       " 'that',\n",
       " 'we',\n",
       " 'until',\n",
       " 'namely',\n",
       " 'n‘t',\n",
       " 'am',\n",
       " 'how',\n",
       " 'never',\n",
       " 'nowhere',\n",
       " 'others',\n",
       " 'these',\n",
       " 'will',\n",
       " 'their',\n",
       " 'already',\n",
       " 'seem',\n",
       " 'whereas',\n",
       " 'whoever',\n",
       " 'themselves',\n",
       " 'whom',\n",
       " 'due',\n",
       " 'anywhere',\n",
       " 'almost',\n",
       " 'thereafter',\n",
       " 'always',\n",
       " 'n’t',\n",
       " 'further',\n",
       " 'neither',\n",
       " 'in',\n",
       " 'those',\n",
       " 'eleven',\n",
       " 'really',\n",
       " 'as',\n",
       " 'toward',\n",
       " 'out',\n",
       " 'take',\n",
       " 'done',\n",
       " 'someone',\n",
       " 'yourselves',\n",
       " 'regarding',\n",
       " 'of',\n",
       " \"'ll\",\n",
       " 'everyone',\n",
       " 'why',\n",
       " 'anyway',\n",
       " 'nine',\n",
       " 'beside',\n",
       " 'thence',\n",
       " 'everywhere',\n",
       " 'itself',\n",
       " 'a',\n",
       " 'between',\n",
       " 'three',\n",
       " 'ca',\n",
       " 'thus',\n",
       " 'amount',\n",
       " 'then',\n",
       " 'became',\n",
       " 'herself',\n",
       " 'much',\n",
       " 'thru',\n",
       " 'than',\n",
       " '‘ve',\n",
       " 'becoming',\n",
       " '‘s',\n",
       " 'more',\n",
       " 'call',\n",
       " 'something',\n",
       " 'about',\n",
       " 'show',\n",
       " 'if',\n",
       " 'besides',\n",
       " 'please',\n",
       " 'together',\n",
       " 'whose',\n",
       " 'since',\n",
       " 're',\n",
       " 'nothing',\n",
       " 'into',\n",
       " 'noone',\n",
       " 'across',\n",
       " 'otherwise',\n",
       " 'who',\n",
       " 'or',\n",
       " 'now',\n",
       " 'twenty',\n",
       " 'hers',\n",
       " 'to',\n",
       " 'anyhow',\n",
       " 'over',\n",
       " 'whole',\n",
       " 'myself',\n",
       " 'quite',\n",
       " 'therefore',\n",
       " 'too',\n",
       " 'above',\n",
       " 'another',\n",
       " 'should',\n",
       " 'everything',\n",
       " 'thereby',\n",
       " 'throughout',\n",
       " 'none',\n",
       " 'serious',\n",
       " 'for',\n",
       " 'mostly',\n",
       " 'an',\n",
       " 'own',\n",
       " 'any',\n",
       " \"'ve\",\n",
       " 'though',\n",
       " 'meanwhile',\n",
       " 'his',\n",
       " 'while',\n",
       " 'same',\n",
       " 'your',\n",
       " 'is',\n",
       " 'side',\n",
       " 'whence',\n",
       " 'you',\n",
       " 'by',\n",
       " 'two',\n",
       " 'which',\n",
       " 'top',\n",
       " 'cannot',\n",
       " 'before',\n",
       " 'would',\n",
       " 'mine',\n",
       " 'still',\n",
       " 'does',\n",
       " 'four',\n",
       " 'against',\n",
       " 'except',\n",
       " 'below',\n",
       " 'alone',\n",
       " 'other',\n",
       " 'last',\n",
       " 'put',\n",
       " 'ourselves',\n",
       " 'she',\n",
       " 'therein',\n",
       " 'somewhere']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clearing the NLP model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text for summarization(Deeplearning from Wikipedia)\n",
    "text = \"\"\" \n",
    "Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.[13]\n",
    "\n",
    "In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation. In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face. Importantly, a deep learning process can learn which features to optimally place in which level on its own. (Of course, this does not completely eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.)[1][14]\n",
    "\n",
    "The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited.[2] No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function.[15] Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.\n",
    "\n",
    "Deep learning architectures can be constructed with a greedy layer-by-layer method.[16] Deep learning helps to disentangle these abstractions and pick out which features improve performance.[1]\n",
    "\n",
    "For supervised learning tasks, deep learning methods eliminate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation.\n",
    "\n",
    "Deep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are neural history compressors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' \\n', 'Most', 'modern', 'deep', 'learning', 'models', 'are', 'based', 'on', 'artificial', 'neural', 'networks', ',', 'specifically', 'convolutional', 'neural', 'networks', '(', 'CNN)s', ',', 'although', 'they', 'can', 'also', 'include', 'propositional', 'formulas', 'or', 'latent', 'variables', 'organized', 'layer', '-', 'wise', 'in', 'deep', 'generative', 'models', 'such', 'as', 'the', 'nodes', 'in', 'deep', 'belief', 'networks', 'and', 'deep', 'Boltzmann', 'machines.[13', ']', '\\n\\n', 'In', 'deep', 'learning', ',', 'each', 'level', 'learns', 'to', 'transform', 'its', 'input', 'data', 'into', 'a', 'slightly', 'more', 'abstract', 'and', 'composite', 'representation', '.', 'In', 'an', 'image', 'recognition', 'application', ',', 'the', 'raw', 'input', 'may', 'be', 'a', 'matrix', 'of', 'pixels', ';', 'the', 'first', 'representational', 'layer', 'may', 'abstract', 'the', 'pixels', 'and', 'encode', 'edges', ';', 'the', 'second', 'layer', 'may', 'compose', 'and', 'encode', 'arrangements', 'of', 'edges', ';', 'the', 'third', 'layer', 'may', 'encode', 'a', 'nose', 'and', 'eyes', ';', 'and', 'the', 'fourth', 'layer', 'may', 'recognize', 'that', 'the', 'image', 'contains', 'a', 'face', '.', 'Importantly', ',', 'a', 'deep', 'learning', 'process', 'can', 'learn', 'which', 'features', 'to', 'optimally', 'place', 'in', 'which', 'level', 'on', 'its', 'own', '.', '(', 'Of', 'course', ',', 'this', 'does', 'not', 'completely', 'eliminate', 'the', 'need', 'for', 'hand', '-', 'tuning', ';', 'for', 'example', ',', 'varying', 'numbers', 'of', 'layers', 'and', 'layer', 'sizes', 'can', 'provide', 'different', 'degrees', 'of', 'abstraction.)[1][14', ']', '\\n\\n', 'The', 'word', '\"', 'deep', '\"', 'in', '\"', 'deep', 'learning', '\"', 'refers', 'to', 'the', 'number', 'of', 'layers', 'through', 'which', 'the', 'data', 'is', 'transformed', '.', 'More', 'precisely', ',', 'deep', 'learning', 'systems', 'have', 'a', 'substantial', 'credit', 'assignment', 'path', '(', 'CAP', ')', 'depth', '.', 'The', 'CAP', 'is', 'the', 'chain', 'of', 'transformations', 'from', 'input', 'to', 'output', '.', 'CAPs', 'describe', 'potentially', 'causal', 'connections', 'between', 'input', 'and', 'output', '.', 'For', 'a', 'feedforward', 'neural', 'network', ',', 'the', 'depth', 'of', 'the', 'CAPs', 'is', 'that', 'of', 'the', 'network', 'and', 'is', 'the', 'number', 'of', 'hidden', 'layers', 'plus', 'one', '(', 'as', 'the', 'output', 'layer', 'is', 'also', 'parameterized', ')', '.', 'For', 'recurrent', 'neural', 'networks', ',', 'in', 'which', 'a', 'signal', 'may', 'propagate', 'through', 'a', 'layer', 'more', 'than', 'once', ',', 'the', 'CAP', 'depth', 'is', 'potentially', 'unlimited.[2', ']', 'No', 'universally', 'agreed', '-', 'upon', 'threshold', 'of', 'depth', 'divides', 'shallow', 'learning', 'from', 'deep', 'learning', ',', 'but', 'most', 'researchers', 'agree', 'that', 'deep', 'learning', 'involves', 'CAP', 'depth', 'higher', 'than', '2', '.', 'CAP', 'of', 'depth', '2', 'has', 'been', 'shown', 'to', 'be', 'a', 'universal', 'approximator', 'in', 'the', 'sense', 'that', 'it', 'can', 'emulate', 'any', 'function.[15', ']', 'Beyond', 'that', ',', 'more', 'layers', 'do', 'not', 'add', 'to', 'the', 'function', 'approximator', 'ability', 'of', 'the', 'network', '.', 'Deep', 'models', '(', 'CAP', '>', '2', ')', 'are', 'able', 'to', 'extract', 'better', 'features', 'than', 'shallow', 'models', 'and', 'hence', ',', 'extra', 'layers', 'help', 'in', 'learning', 'the', 'features', 'effectively', '.', '\\n\\n', 'Deep', 'learning', 'architectures', 'can', 'be', 'constructed', 'with', 'a', 'greedy', 'layer', '-', 'by', '-', 'layer', 'method.[16', ']', 'Deep', 'learning', 'helps', 'to', 'disentangle', 'these', 'abstractions', 'and', 'pick', 'out', 'which', 'features', 'improve', 'performance.[1', ']', '\\n\\n', 'For', 'supervised', 'learning', 'tasks', ',', 'deep', 'learning', 'methods', 'eliminate', 'feature', 'engineering', ',', 'by', 'translating', 'the', 'data', 'into', 'compact', 'intermediate', 'representations', 'akin', 'to', 'principal', 'components', ',', 'and', 'derive', 'layered', 'structures', 'that', 'remove', 'redundancy', 'in', 'representation', '.', '\\n\\n', 'Deep', 'learning', 'algorithms', 'can', 'be', 'applied', 'to', 'unsupervised', 'learning', 'tasks', '.', 'This', 'is', 'an', 'important', 'benefit', 'because', 'unlabeled', 'data', 'are', 'more', 'abundant', 'than', 'the', 'labeled', 'data', '.', 'Examples', 'of', 'deep', 'structures', 'that', 'can', 'be', 'trained', 'in', 'an', 'unsupervised', 'manner', 'are', 'neural', 'history', 'compressors', '\\n']\n"
     ]
    }
   ],
   "source": [
    "# creating a list\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation =  punctuation + '\\n'\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Tokenization\n",
    "word_frequencies = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' \\n': 1, 'modern': 1, 'deep': 13, 'learning': 15, 'models': 4, 'based': 1, 'artificial': 1, 'neural': 5, 'networks': 4, 'specifically': 1, 'convolutional': 1, 'CNN)s': 1, 'include': 1, 'propositional': 1, 'formulas': 1, 'latent': 1, 'variables': 1, 'organized': 1, 'layer': 10, 'wise': 1, 'generative': 1, 'nodes': 1, 'belief': 1, 'Boltzmann': 1, 'machines.[13': 1, '\\n\\n': 5, 'level': 2, 'learns': 1, 'transform': 1, 'input': 4, 'data': 5, 'slightly': 1, 'abstract': 2, 'composite': 1, 'representation': 2, 'image': 2, 'recognition': 1, 'application': 1, 'raw': 1, 'matrix': 1, 'pixels': 2, 'representational': 1, 'encode': 3, 'edges': 2, 'second': 1, 'compose': 1, 'arrangements': 1, 'nose': 1, 'eyes': 1, 'fourth': 1, 'recognize': 1, 'contains': 1, 'face': 1, 'Importantly': 1, 'process': 1, 'learn': 1, 'features': 4, 'optimally': 1, 'place': 1, 'course': 1, 'completely': 1, 'eliminate': 2, 'need': 1, 'hand': 1, 'tuning': 1, 'example': 1, 'varying': 1, 'numbers': 1, 'layers': 5, 'sizes': 1, 'provide': 1, 'different': 1, 'degrees': 1, 'abstraction.)[1][14': 1, 'word': 1, 'refers': 1, 'number': 2, 'transformed': 1, 'precisely': 1, 'systems': 1, 'substantial': 1, 'credit': 1, 'assignment': 1, 'path': 1, 'CAP': 6, 'depth': 6, 'chain': 1, 'transformations': 1, 'output': 3, 'CAPs': 2, 'describe': 1, 'potentially': 2, 'causal': 1, 'connections': 1, 'feedforward': 1, 'network': 3, 'hidden': 1, 'plus': 1, 'parameterized': 1, 'recurrent': 1, 'signal': 1, 'propagate': 1, 'unlimited.[2': 1, 'universally': 1, 'agreed': 1, 'threshold': 1, 'divides': 1, 'shallow': 2, 'researchers': 1, 'agree': 1, 'involves': 1, 'higher': 1, '2': 3, 'shown': 1, 'universal': 1, 'approximator': 2, 'sense': 1, 'emulate': 1, 'function.[15': 1, 'add': 1, 'function': 1, 'ability': 1, 'Deep': 4, 'able': 1, 'extract': 1, 'better': 1, 'extra': 1, 'help': 1, 'effectively': 1, 'architectures': 1, 'constructed': 1, 'greedy': 1, 'method.[16': 1, 'helps': 1, 'disentangle': 1, 'abstractions': 1, 'pick': 1, 'improve': 1, 'performance.[1': 1, 'supervised': 1, 'tasks': 2, 'methods': 1, 'feature': 1, 'engineering': 1, 'translating': 1, 'compact': 1, 'intermediate': 1, 'representations': 1, 'akin': 1, 'principal': 1, 'components': 1, 'derive': 1, 'layered': 1, 'structures': 2, 'remove': 1, 'redundancy': 1, 'algorithms': 1, 'applied': 1, 'unsupervised': 2, 'important': 1, 'benefit': 1, 'unlabeled': 1, 'abundant': 1, 'labeled': 1, 'Examples': 1, 'trained': 1, 'manner': 1, 'history': 1, 'compressors': 1}\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frequency = max(word_frequencies.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' \\n': 0.06666666666666667, 'modern': 0.06666666666666667, 'deep': 0.8666666666666667, 'learning': 1.0, 'models': 0.26666666666666666, 'based': 0.06666666666666667, 'artificial': 0.06666666666666667, 'neural': 0.3333333333333333, 'networks': 0.26666666666666666, 'specifically': 0.06666666666666667, 'convolutional': 0.06666666666666667, 'CNN)s': 0.06666666666666667, 'include': 0.06666666666666667, 'propositional': 0.06666666666666667, 'formulas': 0.06666666666666667, 'latent': 0.06666666666666667, 'variables': 0.06666666666666667, 'organized': 0.06666666666666667, 'layer': 0.6666666666666666, 'wise': 0.06666666666666667, 'generative': 0.06666666666666667, 'nodes': 0.06666666666666667, 'belief': 0.06666666666666667, 'Boltzmann': 0.06666666666666667, 'machines.[13': 0.06666666666666667, '\\n\\n': 0.3333333333333333, 'level': 0.13333333333333333, 'learns': 0.06666666666666667, 'transform': 0.06666666666666667, 'input': 0.26666666666666666, 'data': 0.3333333333333333, 'slightly': 0.06666666666666667, 'abstract': 0.13333333333333333, 'composite': 0.06666666666666667, 'representation': 0.13333333333333333, 'image': 0.13333333333333333, 'recognition': 0.06666666666666667, 'application': 0.06666666666666667, 'raw': 0.06666666666666667, 'matrix': 0.06666666666666667, 'pixels': 0.13333333333333333, 'representational': 0.06666666666666667, 'encode': 0.2, 'edges': 0.13333333333333333, 'second': 0.06666666666666667, 'compose': 0.06666666666666667, 'arrangements': 0.06666666666666667, 'nose': 0.06666666666666667, 'eyes': 0.06666666666666667, 'fourth': 0.06666666666666667, 'recognize': 0.06666666666666667, 'contains': 0.06666666666666667, 'face': 0.06666666666666667, 'Importantly': 0.06666666666666667, 'process': 0.06666666666666667, 'learn': 0.06666666666666667, 'features': 0.26666666666666666, 'optimally': 0.06666666666666667, 'place': 0.06666666666666667, 'course': 0.06666666666666667, 'completely': 0.06666666666666667, 'eliminate': 0.13333333333333333, 'need': 0.06666666666666667, 'hand': 0.06666666666666667, 'tuning': 0.06666666666666667, 'example': 0.06666666666666667, 'varying': 0.06666666666666667, 'numbers': 0.06666666666666667, 'layers': 0.3333333333333333, 'sizes': 0.06666666666666667, 'provide': 0.06666666666666667, 'different': 0.06666666666666667, 'degrees': 0.06666666666666667, 'abstraction.)[1][14': 0.06666666666666667, 'word': 0.06666666666666667, 'refers': 0.06666666666666667, 'number': 0.13333333333333333, 'transformed': 0.06666666666666667, 'precisely': 0.06666666666666667, 'systems': 0.06666666666666667, 'substantial': 0.06666666666666667, 'credit': 0.06666666666666667, 'assignment': 0.06666666666666667, 'path': 0.06666666666666667, 'CAP': 0.4, 'depth': 0.4, 'chain': 0.06666666666666667, 'transformations': 0.06666666666666667, 'output': 0.2, 'CAPs': 0.13333333333333333, 'describe': 0.06666666666666667, 'potentially': 0.13333333333333333, 'causal': 0.06666666666666667, 'connections': 0.06666666666666667, 'feedforward': 0.06666666666666667, 'network': 0.2, 'hidden': 0.06666666666666667, 'plus': 0.06666666666666667, 'parameterized': 0.06666666666666667, 'recurrent': 0.06666666666666667, 'signal': 0.06666666666666667, 'propagate': 0.06666666666666667, 'unlimited.[2': 0.06666666666666667, 'universally': 0.06666666666666667, 'agreed': 0.06666666666666667, 'threshold': 0.06666666666666667, 'divides': 0.06666666666666667, 'shallow': 0.13333333333333333, 'researchers': 0.06666666666666667, 'agree': 0.06666666666666667, 'involves': 0.06666666666666667, 'higher': 0.06666666666666667, '2': 0.2, 'shown': 0.06666666666666667, 'universal': 0.06666666666666667, 'approximator': 0.13333333333333333, 'sense': 0.06666666666666667, 'emulate': 0.06666666666666667, 'function.[15': 0.06666666666666667, 'add': 0.06666666666666667, 'function': 0.06666666666666667, 'ability': 0.06666666666666667, 'Deep': 0.26666666666666666, 'able': 0.06666666666666667, 'extract': 0.06666666666666667, 'better': 0.06666666666666667, 'extra': 0.06666666666666667, 'help': 0.06666666666666667, 'effectively': 0.06666666666666667, 'architectures': 0.06666666666666667, 'constructed': 0.06666666666666667, 'greedy': 0.06666666666666667, 'method.[16': 0.06666666666666667, 'helps': 0.06666666666666667, 'disentangle': 0.06666666666666667, 'abstractions': 0.06666666666666667, 'pick': 0.06666666666666667, 'improve': 0.06666666666666667, 'performance.[1': 0.06666666666666667, 'supervised': 0.06666666666666667, 'tasks': 0.13333333333333333, 'methods': 0.06666666666666667, 'feature': 0.06666666666666667, 'engineering': 0.06666666666666667, 'translating': 0.06666666666666667, 'compact': 0.06666666666666667, 'intermediate': 0.06666666666666667, 'representations': 0.06666666666666667, 'akin': 0.06666666666666667, 'principal': 0.06666666666666667, 'components': 0.06666666666666667, 'derive': 0.06666666666666667, 'layered': 0.06666666666666667, 'structures': 0.13333333333333333, 'remove': 0.06666666666666667, 'redundancy': 0.06666666666666667, 'algorithms': 0.06666666666666667, 'applied': 0.06666666666666667, 'unsupervised': 0.13333333333333333, 'important': 0.06666666666666667, 'benefit': 0.06666666666666667, 'unlabeled': 0.06666666666666667, 'abundant': 0.06666666666666667, 'labeled': 0.06666666666666667, 'Examples': 0.06666666666666667, 'trained': 0.06666666666666667, 'manner': 0.06666666666666667, 'history': 0.06666666666666667, 'compressors': 0.06666666666666667}\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \n",
      "Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.[13]\n",
      "\n",
      "In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation., In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face., Importantly, a deep learning process can learn which features to optimally place in which level on its own., (Of course, this does not completely eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.)[1][14], \n",
      "\n",
      "The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed., More precisely, deep learning systems have a substantial credit assignment path (CAP) depth., The CAP is the chain of transformations from input to output., CAPs describe potentially causal connections between input and output., For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized)., For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited.[2], No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2., CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function.[15] Beyond that, more layers do not add to the function approximator ability of the network., Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively., \n",
      "\n",
      "Deep learning architectures can be constructed with a greedy layer-by-layer method.[16], Deep learning helps to disentangle these abstractions and pick out which features improve performance.[1]\n",
      "\n",
      "For supervised learning tasks, deep learning methods eliminate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation., \n",
      "\n",
      "Deep learning algorithms can be applied to unsupervised learning tasks., This is an important benefit because unlabeled data are more abundant than the labeled data., Examples of deep structures that can be trained in an unsupervised manner are neural history compressors\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "sentence_tokens = [sent for sent in doc.sents]\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ \n",
       " Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.[13]\n",
       " \n",
       " In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation.: 11.733333333333333,\n",
       " In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face.: 5.4,\n",
       " Importantly, a deep learning process can learn which features to optimally place in which level on its own.: 2.5333333333333337,\n",
       " (Of course, this does not completely eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.)[1][14]: 1.9999999999999998,\n",
       " \n",
       " \n",
       " The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed.: 4.066666666666666,\n",
       " More precisely, deep learning systems have a substantial credit assignment path (CAP) depth.: 2.6666666666666674,\n",
       " The CAP is the chain of transformations from input to output.: 0.6000000000000001,\n",
       " CAPs describe potentially causal connections between input and output.: 0.8,\n",
       " For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized).: 2.7333333333333334,\n",
       " For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited.[2]: 2.066666666666667,\n",
       " No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2.: 6.400000000000001,\n",
       " CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function.[15] Beyond that, more layers do not add to the function approximator ability of the network.: 1.9333333333333331,\n",
       " Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.: 4.0,\n",
       " \n",
       " \n",
       " Deep learning architectures can be constructed with a greedy layer-by-layer method.[16]: 3.8000000000000007,\n",
       " Deep learning helps to disentangle these abstractions and pick out which features improve performance.[1]\n",
       " \n",
       " For supervised learning tasks, deep learning methods eliminate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation.: 7.6,\n",
       " \n",
       " \n",
       " Deep learning algorithms can be applied to unsupervised learning tasks.: 3.6000000000000005,\n",
       " This is an important benefit because unlabeled data are more abundant than the labeled data.: 1.0,\n",
       " Examples of deep structures that can be trained in an unsupervised manner are neural history compressors: 1.7333333333333332}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_length = int(len(sentence_tokens)*0.3)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ \n",
       " Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.[13]\n",
       " \n",
       " In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation.,\n",
       " Deep learning helps to disentangle these abstractions and pick out which features improve performance.[1]\n",
       " \n",
       " For supervised learning tasks, deep learning methods eliminate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation.,\n",
       " No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2.,\n",
       " In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face.,\n",
       " \n",
       " \n",
       " The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed.]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = [word.text for word in summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = ''.join(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.[13]\n",
      "\n",
      "In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation. In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face. Importantly, a deep learning process can learn which features to optimally place in which level on its own. (Of course, this does not completely eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.)[1][14]\n",
      "\n",
      "The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited.[2] No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2. CAP of depth 2 has been shown to be a universal approximator in the sense that it can emulate any function.[15] Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > 2) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.\n",
      "\n",
      "Deep learning architectures can be constructed with a greedy layer-by-layer method.[16] Deep learning helps to disentangle these abstractions and pick out which features improve performance.[1]\n",
      "\n",
      "For supervised learning tasks, deep learning methods eliminate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation.\n",
      "\n",
      "Deep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are neural history compressors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.[13]\n",
      "\n",
      "In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation.Deep learning helps to disentangle these abstractions and pick out which features improve performance.[1]\n",
      "\n",
      "For supervised learning tasks, deep learning methods eliminate feature engineering, by translating the data into compact intermediate representations akin to principal components, and derive layered structures that remove redundancy in representation.No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than 2.In an image recognition application, the raw input may be a matrix of pixels; the first representational layer may abstract the pixels and encode edges; the second layer may compose and encode arrangements of edges; the third layer may encode a nose and eyes; and the fourth layer may recognize that the image contains a face.\n",
      "\n",
      "The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2939"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1407"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
